{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-31T11:42:59.544637Z",
     "iopub.status.busy": "2025-07-31T11:42:59.544253Z",
     "iopub.status.idle": "2025-07-31T11:42:59.871804Z",
     "shell.execute_reply": "2025-07-31T11:42:59.871253Z",
     "shell.execute_reply.started": "2025-07-31T11:42:59.544601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2025/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2025/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2025/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2025/sample_submission.json\n",
      "/kaggle/input/arc-prize-2025/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T11:43:02.540728Z",
     "iopub.status.busy": "2025-07-31T11:43:02.539967Z",
     "iopub.status.idle": "2025-07-31T11:46:49.997791Z",
     "shell.execute_reply": "2025-07-31T11:46:49.997228Z",
     "shell.execute_reply.started": "2025-07-31T11:43:02.540701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading ARC AGI data...\n",
      "First Problem ID: 0934a4d8\n",
      "First Pair:\n",
      "{'input': [[3,\n",
      "            5,\n",
      "            3,\n",
      "            3,\n",
      "            6,\n",
      "            6,\n",
      "            5,\n",
      "            4,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            4,\n",
      "            5,\n",
      "            6,\n",
      "            6,\n",
      "            3,\n",
      "            3],\n",
      "           [5,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            6,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            6,\n",
      "            3,\n",
      "            3],\n",
      "           [1,\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            6,\n",
      "            9,\n",
      "            1,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            6,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            3],\n",
      "           [1,\n",
      "            1,\n",
      "            5,\n",
      "            3,\n",
      "            4,\n",
      "            5,\n",
      "            6,\n",
      "            6,\n",
      "            1,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            6,\n",
      "            6,\n",
      "            5,\n",
      "            4,\n",
      "            3,\n",
      "            5],\n",
      "           [6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            5,\n",
      "            3,\n",
      "            3,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            2,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            2,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            3,\n",
      "            3,\n",
      "            5,\n",
      "            3,\n",
      "            9,\n",
      "            9],\n",
      "           [9,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            5,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            1,\n",
      "            9,\n",
      "            4,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            5,\n",
      "            9,\n",
      "            9],\n",
      "           [9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            1,\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            4,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            2,\n",
      "            2,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            4,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            5,\n",
      "            3,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            6],\n",
      "           [9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            1,\n",
      "            1,\n",
      "            5,\n",
      "            3,\n",
      "            9,\n",
      "            1,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            4,\n",
      "            5,\n",
      "            1,\n",
      "            9,\n",
      "            3,\n",
      "            5,\n",
      "            1,\n",
      "            1,\n",
      "            6,\n",
      "            9],\n",
      "           [1,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            5,\n",
      "            5,\n",
      "            7,\n",
      "            2,\n",
      "            4,\n",
      "            3,\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            2,\n",
      "            7,\n",
      "            5,\n",
      "            5,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            1,\n",
      "            9],\n",
      "           [4,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            5,\n",
      "            2,\n",
      "            7,\n",
      "            3,\n",
      "            4,\n",
      "            4,\n",
      "            2,\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "            3,\n",
      "            7,\n",
      "            2,\n",
      "            5,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            1],\n",
      "           [9,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            5,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "            3,\n",
      "            3,\n",
      "            4,\n",
      "            4,\n",
      "            2,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            1],\n",
      "           [9,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            4,\n",
      "            3,\n",
      "            2,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4],\n",
      "           [4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            5,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            5,\n",
      "            5,\n",
      "            7,\n",
      "            2,\n",
      "            2,\n",
      "            7,\n",
      "            5,\n",
      "            5,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            5,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            9],\n",
      "           [3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            2,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            5,\n",
      "            7,\n",
      "            7,\n",
      "            4,\n",
      "            5,\n",
      "            2,\n",
      "            7,\n",
      "            7,\n",
      "            2,\n",
      "            5,\n",
      "            4,\n",
      "            7,\n",
      "            7,\n",
      "            5,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            2,\n",
      "            1,\n",
      "            9],\n",
      "           [9,\n",
      "            9,\n",
      "            4,\n",
      "            4,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            5,\n",
      "            9,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            9,\n",
      "            5,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            4],\n",
      "           [9,\n",
      "            1,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            6,\n",
      "            2,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            5],\n",
      "           [9,\n",
      "            1,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            6,\n",
      "            2,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            5],\n",
      "           [9,\n",
      "            9,\n",
      "            4,\n",
      "            4,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            5,\n",
      "            9,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            9,\n",
      "            5,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            4],\n",
      "           [3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            2,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            5,\n",
      "            7,\n",
      "            7,\n",
      "            4,\n",
      "            5,\n",
      "            2,\n",
      "            7,\n",
      "            7,\n",
      "            2,\n",
      "            5,\n",
      "            4,\n",
      "            7,\n",
      "            7,\n",
      "            5,\n",
      "            9,\n",
      "            6,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            9],\n",
      "           [4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            5,\n",
      "            9,\n",
      "            7,\n",
      "            7,\n",
      "            5,\n",
      "            5,\n",
      "            7,\n",
      "            2,\n",
      "            2,\n",
      "            7,\n",
      "            5,\n",
      "            5,\n",
      "            7,\n",
      "            7,\n",
      "            9,\n",
      "            5,\n",
      "            9,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            9],\n",
      "           [9,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            4,\n",
      "            3,\n",
      "            2,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            5,\n",
      "            4,\n",
      "            4,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            4],\n",
      "           [9,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            5,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "            3,\n",
      "            3,\n",
      "            4,\n",
      "            4,\n",
      "            2,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            5,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            1],\n",
      "           [4,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            5,\n",
      "            2,\n",
      "            7,\n",
      "            3,\n",
      "            4,\n",
      "            4,\n",
      "            2,\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "            3,\n",
      "            7,\n",
      "            2,\n",
      "            5,\n",
      "            4,\n",
      "            1,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            8,\n",
      "            1],\n",
      "           [1,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            5,\n",
      "            5,\n",
      "            7,\n",
      "            2,\n",
      "            4,\n",
      "            3,\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            2,\n",
      "            7,\n",
      "            5,\n",
      "            5,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            1,\n",
      "            9],\n",
      "           [9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            1,\n",
      "            1,\n",
      "            5,\n",
      "            3,\n",
      "            9,\n",
      "            1,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            4,\n",
      "            5,\n",
      "            1,\n",
      "            9,\n",
      "            3,\n",
      "            5,\n",
      "            1,\n",
      "            1,\n",
      "            6,\n",
      "            9],\n",
      "           [9,\n",
      "            9,\n",
      "            6,\n",
      "            9,\n",
      "            1,\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            4,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            2,\n",
      "            2,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            4,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            5,\n",
      "            3,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            6],\n",
      "           [9,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            5,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            1,\n",
      "            9,\n",
      "            4,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "            5,\n",
      "            9,\n",
      "            9],\n",
      "           [6,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            5,\n",
      "            3,\n",
      "            3,\n",
      "            4,\n",
      "            3,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            2,\n",
      "            6,\n",
      "            9,\n",
      "            9,\n",
      "            6,\n",
      "            2,\n",
      "            9,\n",
      "            9,\n",
      "            9,\n",
      "            3,\n",
      "            4,\n",
      "            3,\n",
      "            3,\n",
      "            5,\n",
      "            3,\n",
      "            9,\n",
      "            9],\n",
      "           [1,\n",
      "            1,\n",
      "            5,\n",
      "            3,\n",
      "            4,\n",
      "            5,\n",
      "            6,\n",
      "            6,\n",
      "            1,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            4,\n",
      "            1,\n",
      "            9,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            1,\n",
      "            6,\n",
      "            6,\n",
      "            5,\n",
      "            4,\n",
      "            3,\n",
      "            5],\n",
      "           [1,\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            6,\n",
      "            6,\n",
      "            9,\n",
      "            1,\n",
      "            1,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            4,\n",
      "            9,\n",
      "            9,\n",
      "            4,\n",
      "            1,\n",
      "            1,\n",
      "            9,\n",
      "            6,\n",
      "            6,\n",
      "            4,\n",
      "            5,\n",
      "            5,\n",
      "            3]],\n",
      " 'output': [[9, 9, 6, 4],\n",
      "            [2, 6, 9, 4],\n",
      "            [2, 6, 9, 4],\n",
      "            [9, 9, 6, 4],\n",
      "            [9, 9, 2, 1],\n",
      "            [6, 9, 9, 9],\n",
      "            [4, 1, 9, 1],\n",
      "            [4, 9, 9, 4],\n",
      "            [9, 4, 3, 9]]}\n",
      "First Input shape: torch.Size([30, 30, 10])\n",
      "First Output shape: torch.Size([30, 30, 10])\n",
      "Loaded 120 training pairs and 120 test inputs.\n",
      "Model parameters: 3,535,946\n",
      "Found existing checkpoint from epoch 760 with loss: 0.0981\n",
      "Training for 1000 epochs starting from epoch 0...\n",
      "Epoch [1/1000], New best loss: 2.1118 - Model saved!\n",
      "Epoch [2/1000], New best loss: 1.4636 - Model saved!\n",
      "Epoch [3/1000], New best loss: 1.3066 - Model saved!\n",
      "Epoch [4/1000], New best loss: 1.1952 - Model saved!\n",
      "Epoch [5/1000], New best loss: 1.1593 - Model saved!\n",
      "Epoch [6/1000], New best loss: 1.0964 - Model saved!\n",
      "Epoch [7/1000], New best loss: 1.0855 - Model saved!\n",
      "Epoch [8/1000], New best loss: 1.0736 - Model saved!\n",
      "Epoch [9/1000], New best loss: 1.0724 - Model saved!\n",
      "Epoch [10/1000], Loss: 1.0783\n",
      "Epoch [12/1000], New best loss: 1.0660 - Model saved!\n",
      "Epoch [15/1000], New best loss: 1.0633 - Model saved!\n",
      "Epoch [16/1000], New best loss: 1.0080 - Model saved!\n",
      "Epoch [18/1000], New best loss: 0.9635 - Model saved!\n",
      "Epoch [20/1000], Loss: 0.9924\n",
      "Epoch [24/1000], New best loss: 0.9505 - Model saved!\n",
      "Epoch [25/1000], New best loss: 0.9479 - Model saved!\n",
      "Epoch [27/1000], New best loss: 0.9448 - Model saved!\n",
      "Epoch [28/1000], New best loss: 0.9276 - Model saved!\n",
      "Epoch [30/1000], Loss: 0.9381\n",
      "Epoch [31/1000], New best loss: 0.9035 - Model saved!\n",
      "Epoch [32/1000], New best loss: 0.8939 - Model saved!\n",
      "Epoch [34/1000], New best loss: 0.8844 - Model saved!\n",
      "Epoch [35/1000], New best loss: 0.8810 - Model saved!\n",
      "Epoch [36/1000], New best loss: 0.8760 - Model saved!\n",
      "Epoch [37/1000], New best loss: 0.8728 - Model saved!\n",
      "Epoch [39/1000], New best loss: 0.8690 - Model saved!\n",
      "Epoch [40/1000], New best loss: 0.8615 - Model saved!\n",
      "Epoch [40/1000], Loss: 0.8615\n",
      "Epoch [42/1000], New best loss: 0.8442 - Model saved!\n",
      "Epoch [43/1000], New best loss: 0.8439 - Model saved!\n",
      "Epoch [45/1000], New best loss: 0.8327 - Model saved!\n",
      "Epoch [49/1000], New best loss: 0.8052 - Model saved!\n",
      "Epoch [50/1000], New best loss: 0.7983 - Model saved!\n",
      "Epoch [50/1000], Loss: 0.7983\n",
      "Epoch [57/1000], New best loss: 0.7958 - Model saved!\n",
      "Epoch [59/1000], New best loss: 0.7868 - Model saved!\n",
      "Epoch [60/1000], New best loss: 0.7800 - Model saved!\n",
      "Epoch [60/1000], Loss: 0.7800\n",
      "Epoch [61/1000], New best loss: 0.7568 - Model saved!\n",
      "Epoch [62/1000], New best loss: 0.7439 - Model saved!\n",
      "Epoch [63/1000], New best loss: 0.7342 - Model saved!\n",
      "Epoch [65/1000], New best loss: 0.7323 - Model saved!\n",
      "Epoch [66/1000], New best loss: 0.7261 - Model saved!\n",
      "Epoch [67/1000], New best loss: 0.7117 - Model saved!\n",
      "Epoch [68/1000], New best loss: 0.7088 - Model saved!\n",
      "Epoch [69/1000], New best loss: 0.7051 - Model saved!\n",
      "Epoch [70/1000], New best loss: 0.7050 - Model saved!\n",
      "Epoch [70/1000], Loss: 0.7050\n",
      "Epoch [71/1000], New best loss: 0.7012 - Model saved!\n",
      "Epoch [72/1000], New best loss: 0.6946 - Model saved!\n",
      "Epoch [74/1000], New best loss: 0.6934 - Model saved!\n",
      "Epoch [75/1000], New best loss: 0.6883 - Model saved!\n",
      "Epoch [76/1000], New best loss: 0.6771 - Model saved!\n",
      "Epoch [80/1000], Loss: 0.6815\n",
      "Epoch [81/1000], New best loss: 0.6683 - Model saved!\n",
      "Epoch [82/1000], New best loss: 0.6620 - Model saved!\n",
      "Epoch [85/1000], New best loss: 0.6588 - Model saved!\n",
      "Epoch [86/1000], New best loss: 0.6536 - Model saved!\n",
      "Epoch [87/1000], New best loss: 0.6439 - Model saved!\n",
      "Epoch [88/1000], New best loss: 0.6295 - Model saved!\n",
      "Epoch [89/1000], New best loss: 0.6277 - Model saved!\n",
      "Epoch [90/1000], New best loss: 0.6235 - Model saved!\n",
      "Epoch [90/1000], Loss: 0.6235\n",
      "Epoch [91/1000], New best loss: 0.6105 - Model saved!\n",
      "Epoch [92/1000], New best loss: 0.5986 - Model saved!\n",
      "Epoch [94/1000], New best loss: 0.5914 - Model saved!\n",
      "Epoch [95/1000], New best loss: 0.5845 - Model saved!\n",
      "Epoch [96/1000], New best loss: 0.5819 - Model saved!\n",
      "Epoch [98/1000], New best loss: 0.5804 - Model saved!\n",
      "Epoch [99/1000], New best loss: 0.5783 - Model saved!\n",
      "Epoch [100/1000], New best loss: 0.5697 - Model saved!\n",
      "Epoch [100/1000], Loss: 0.5697\n",
      "Epoch [101/1000], New best loss: 0.5687 - Model saved!\n",
      "Epoch [102/1000], New best loss: 0.5574 - Model saved!\n",
      "Epoch [103/1000], New best loss: 0.5531 - Model saved!\n",
      "Epoch [104/1000], New best loss: 0.5495 - Model saved!\n",
      "Epoch [106/1000], New best loss: 0.5492 - Model saved!\n",
      "Epoch [107/1000], New best loss: 0.5467 - Model saved!\n",
      "Epoch [108/1000], New best loss: 0.5393 - Model saved!\n",
      "Epoch [109/1000], New best loss: 0.5369 - Model saved!\n",
      "Epoch [110/1000], Loss: 0.5398\n",
      "Epoch [112/1000], New best loss: 0.5346 - Model saved!\n",
      "Epoch [113/1000], New best loss: 0.5294 - Model saved!\n",
      "Epoch [114/1000], New best loss: 0.5253 - Model saved!\n",
      "Epoch [115/1000], New best loss: 0.5252 - Model saved!\n",
      "Epoch [120/1000], Loss: 0.5333\n",
      "Epoch [121/1000], New best loss: 0.5238 - Model saved!\n",
      "Epoch [122/1000], New best loss: 0.5131 - Model saved!\n",
      "Epoch [123/1000], New best loss: 0.5098 - Model saved!\n",
      "Epoch [124/1000], New best loss: 0.5076 - Model saved!\n",
      "Epoch [125/1000], New best loss: 0.5060 - Model saved!\n",
      "Epoch [126/1000], New best loss: 0.5040 - Model saved!\n",
      "Epoch [127/1000], New best loss: 0.5034 - Model saved!\n",
      "Epoch [128/1000], New best loss: 0.5011 - Model saved!\n",
      "Epoch [129/1000], New best loss: 0.5001 - Model saved!\n",
      "Epoch [130/1000], New best loss: 0.4983 - Model saved!\n",
      "Epoch [130/1000], Loss: 0.4983\n",
      "Epoch [131/1000], New best loss: 0.4967 - Model saved!\n",
      "Epoch [132/1000], New best loss: 0.4964 - Model saved!\n",
      "Epoch [133/1000], New best loss: 0.4960 - Model saved!\n",
      "Epoch [134/1000], New best loss: 0.4936 - Model saved!\n",
      "Epoch [135/1000], New best loss: 0.4925 - Model saved!\n",
      "Epoch [136/1000], New best loss: 0.4912 - Model saved!\n",
      "Epoch [137/1000], New best loss: 0.4894 - Model saved!\n",
      "Epoch [138/1000], New best loss: 0.4883 - Model saved!\n",
      "Epoch [139/1000], New best loss: 0.4864 - Model saved!\n",
      "Epoch [140/1000], New best loss: 0.4852 - Model saved!\n",
      "Epoch [140/1000], Loss: 0.4852\n",
      "Epoch [141/1000], New best loss: 0.4841 - Model saved!\n",
      "Epoch [143/1000], New best loss: 0.4816 - Model saved!\n",
      "Epoch [144/1000], New best loss: 0.4811 - Model saved!\n",
      "Epoch [145/1000], New best loss: 0.4799 - Model saved!\n",
      "Epoch [146/1000], New best loss: 0.4797 - Model saved!\n",
      "Epoch [147/1000], New best loss: 0.4775 - Model saved!\n",
      "Epoch [149/1000], New best loss: 0.4754 - Model saved!\n",
      "Epoch [150/1000], New best loss: 0.4711 - Model saved!\n",
      "Epoch [150/1000], Loss: 0.4711\n",
      "Epoch [151/1000], New best loss: 0.4691 - Model saved!\n",
      "Epoch [152/1000], New best loss: 0.4656 - Model saved!\n",
      "Epoch [153/1000], New best loss: 0.4643 - Model saved!\n",
      "Epoch [154/1000], New best loss: 0.4630 - Model saved!\n",
      "Epoch [155/1000], New best loss: 0.4620 - Model saved!\n",
      "Epoch [156/1000], New best loss: 0.4610 - Model saved!\n",
      "Epoch [157/1000], New best loss: 0.4601 - Model saved!\n",
      "Epoch [158/1000], New best loss: 0.4590 - Model saved!\n",
      "Epoch [159/1000], New best loss: 0.4580 - Model saved!\n",
      "Epoch [160/1000], New best loss: 0.4570 - Model saved!\n",
      "Epoch [160/1000], Loss: 0.4570\n",
      "Epoch [161/1000], New best loss: 0.4554 - Model saved!\n",
      "Epoch [162/1000], New best loss: 0.4548 - Model saved!\n",
      "Epoch [163/1000], New best loss: 0.4541 - Model saved!\n",
      "Epoch [164/1000], New best loss: 0.4528 - Model saved!\n",
      "Epoch [165/1000], New best loss: 0.4511 - Model saved!\n",
      "Epoch [166/1000], New best loss: 0.4501 - Model saved!\n",
      "Epoch [167/1000], New best loss: 0.4488 - Model saved!\n",
      "Epoch [168/1000], New best loss: 0.4482 - Model saved!\n",
      "Epoch [169/1000], New best loss: 0.4471 - Model saved!\n",
      "Epoch [170/1000], New best loss: 0.4451 - Model saved!\n",
      "Epoch [170/1000], Loss: 0.4451\n",
      "Epoch [171/1000], New best loss: 0.4439 - Model saved!\n",
      "Epoch [172/1000], New best loss: 0.4433 - Model saved!\n",
      "Epoch [174/1000], New best loss: 0.4415 - Model saved!\n",
      "Epoch [175/1000], New best loss: 0.4412 - Model saved!\n",
      "Epoch [176/1000], New best loss: 0.4401 - Model saved!\n",
      "Epoch [177/1000], New best loss: 0.4389 - Model saved!\n",
      "Epoch [178/1000], New best loss: 0.4371 - Model saved!\n",
      "Epoch [179/1000], New best loss: 0.4371 - Model saved!\n",
      "Epoch [180/1000], New best loss: 0.4349 - Model saved!\n",
      "Epoch [180/1000], Loss: 0.4349\n",
      "Epoch [181/1000], New best loss: 0.4318 - Model saved!\n",
      "Epoch [182/1000], New best loss: 0.4311 - Model saved!\n",
      "Epoch [183/1000], New best loss: 0.4297 - Model saved!\n",
      "Epoch [184/1000], New best loss: 0.4293 - Model saved!\n",
      "Epoch [185/1000], New best loss: 0.4285 - Model saved!\n",
      "Epoch [186/1000], New best loss: 0.4277 - Model saved!\n",
      "Epoch [187/1000], New best loss: 0.4274 - Model saved!\n",
      "Epoch [188/1000], New best loss: 0.4269 - Model saved!\n",
      "Epoch [189/1000], New best loss: 0.4258 - Model saved!\n",
      "Epoch [190/1000], New best loss: 0.4255 - Model saved!\n",
      "Epoch [190/1000], Loss: 0.4255\n",
      "Epoch [191/1000], New best loss: 0.4247 - Model saved!\n",
      "Epoch [192/1000], New best loss: 0.4241 - Model saved!\n",
      "Epoch [193/1000], New best loss: 0.4241 - Model saved!\n",
      "Epoch [194/1000], New best loss: 0.4229 - Model saved!\n",
      "Epoch [195/1000], New best loss: 0.4226 - Model saved!\n",
      "Epoch [196/1000], New best loss: 0.4223 - Model saved!\n",
      "Epoch [197/1000], New best loss: 0.4214 - Model saved!\n",
      "Epoch [198/1000], New best loss: 0.4210 - Model saved!\n",
      "Epoch [199/1000], New best loss: 0.4204 - Model saved!\n",
      "Epoch [200/1000], New best loss: 0.4194 - Model saved!\n",
      "Epoch [200/1000], Loss: 0.4194\n",
      "Epoch [201/1000], New best loss: 0.4192 - Model saved!\n",
      "Epoch [202/1000], New best loss: 0.4184 - Model saved!\n",
      "Epoch [203/1000], New best loss: 0.4178 - Model saved!\n",
      "Epoch [205/1000], New best loss: 0.4174 - Model saved!\n",
      "Epoch [206/1000], New best loss: 0.4164 - Model saved!\n",
      "Epoch [207/1000], New best loss: 0.4158 - Model saved!\n",
      "Epoch [208/1000], New best loss: 0.4148 - Model saved!\n",
      "Epoch [209/1000], New best loss: 0.4147 - Model saved!\n",
      "Epoch [210/1000], New best loss: 0.4145 - Model saved!\n",
      "Epoch [210/1000], Loss: 0.4145\n",
      "Epoch [211/1000], New best loss: 0.4138 - Model saved!\n",
      "Epoch [212/1000], New best loss: 0.4125 - Model saved!\n",
      "Epoch [213/1000], New best loss: 0.4120 - Model saved!\n",
      "Epoch [214/1000], New best loss: 0.4116 - Model saved!\n",
      "Epoch [215/1000], New best loss: 0.4114 - Model saved!\n",
      "Epoch [216/1000], New best loss: 0.4111 - Model saved!\n",
      "Epoch [217/1000], New best loss: 0.4108 - Model saved!\n",
      "Epoch [218/1000], New best loss: 0.4104 - Model saved!\n",
      "Epoch [219/1000], New best loss: 0.4101 - Model saved!\n",
      "Epoch [220/1000], New best loss: 0.4098 - Model saved!\n",
      "Epoch [220/1000], Loss: 0.4098\n",
      "Epoch [221/1000], New best loss: 0.4098 - Model saved!\n",
      "Epoch [222/1000], New best loss: 0.4092 - Model saved!\n",
      "Epoch [223/1000], New best loss: 0.4089 - Model saved!\n",
      "Epoch [224/1000], New best loss: 0.4087 - Model saved!\n",
      "Epoch [225/1000], New best loss: 0.4087 - Model saved!\n",
      "Epoch [226/1000], New best loss: 0.4081 - Model saved!\n",
      "Epoch [227/1000], New best loss: 0.4077 - Model saved!\n",
      "Epoch [228/1000], New best loss: 0.4074 - Model saved!\n",
      "Epoch [229/1000], New best loss: 0.4071 - Model saved!\n",
      "Epoch [230/1000], New best loss: 0.4068 - Model saved!\n",
      "Epoch [230/1000], Loss: 0.4068\n",
      "Epoch [231/1000], New best loss: 0.4066 - Model saved!\n",
      "Epoch [232/1000], New best loss: 0.4064 - Model saved!\n",
      "Epoch [233/1000], New best loss: 0.4058 - Model saved!\n",
      "Epoch [234/1000], New best loss: 0.4057 - Model saved!\n",
      "Epoch [235/1000], New best loss: 0.4053 - Model saved!\n",
      "Epoch [236/1000], New best loss: 0.4050 - Model saved!\n",
      "Epoch [237/1000], New best loss: 0.4047 - Model saved!\n",
      "Epoch [238/1000], New best loss: 0.4045 - Model saved!\n",
      "Epoch [239/1000], New best loss: 0.4041 - Model saved!\n",
      "Epoch [240/1000], New best loss: 0.4036 - Model saved!\n",
      "Epoch [240/1000], Loss: 0.4036\n",
      "Epoch [241/1000], New best loss: 0.4031 - Model saved!\n",
      "Epoch [242/1000], New best loss: 0.4029 - Model saved!\n",
      "Epoch [243/1000], New best loss: 0.4028 - Model saved!\n",
      "Epoch [244/1000], New best loss: 0.4025 - Model saved!\n",
      "Epoch [245/1000], New best loss: 0.4024 - Model saved!\n",
      "Epoch [246/1000], New best loss: 0.4022 - Model saved!\n",
      "Epoch [247/1000], New best loss: 0.4021 - Model saved!\n",
      "Epoch [248/1000], New best loss: 0.4019 - Model saved!\n",
      "Epoch [249/1000], New best loss: 0.4018 - Model saved!\n",
      "Epoch [250/1000], New best loss: 0.4015 - Model saved!\n",
      "Epoch [250/1000], Loss: 0.4015\n",
      "Epoch [251/1000], New best loss: 0.4013 - Model saved!\n",
      "Epoch [252/1000], New best loss: 0.4012 - Model saved!\n",
      "Epoch [253/1000], New best loss: 0.4010 - Model saved!\n",
      "Epoch [254/1000], New best loss: 0.4008 - Model saved!\n",
      "Epoch [255/1000], New best loss: 0.4007 - Model saved!\n",
      "Epoch [256/1000], New best loss: 0.4005 - Model saved!\n",
      "Epoch [257/1000], New best loss: 0.4004 - Model saved!\n",
      "Epoch [258/1000], New best loss: 0.4002 - Model saved!\n",
      "Epoch [259/1000], New best loss: 0.4001 - Model saved!\n",
      "Epoch [260/1000], New best loss: 0.3999 - Model saved!\n",
      "Epoch [260/1000], Loss: 0.3999\n",
      "Epoch [261/1000], New best loss: 0.3997 - Model saved!\n",
      "Epoch [262/1000], New best loss: 0.3995 - Model saved!\n",
      "Epoch [263/1000], New best loss: 0.3993 - Model saved!\n",
      "Epoch [264/1000], New best loss: 0.3992 - Model saved!\n",
      "Epoch [265/1000], New best loss: 0.3990 - Model saved!\n",
      "Epoch [266/1000], New best loss: 0.3988 - Model saved!\n",
      "Epoch [267/1000], New best loss: 0.3987 - Model saved!\n",
      "Epoch [268/1000], New best loss: 0.3985 - Model saved!\n",
      "Epoch [269/1000], New best loss: 0.3983 - Model saved!\n",
      "Epoch [270/1000], New best loss: 0.3981 - Model saved!\n",
      "Epoch [270/1000], Loss: 0.3981\n",
      "Epoch [271/1000], New best loss: 0.3979 - Model saved!\n",
      "Epoch [272/1000], New best loss: 0.3978 - Model saved!\n",
      "Epoch [273/1000], New best loss: 0.3977 - Model saved!\n",
      "Epoch [274/1000], New best loss: 0.3976 - Model saved!\n",
      "Epoch [275/1000], New best loss: 0.3975 - Model saved!\n",
      "Epoch [276/1000], New best loss: 0.3974 - Model saved!\n",
      "Epoch [277/1000], New best loss: 0.3973 - Model saved!\n",
      "Epoch [278/1000], New best loss: 0.3973 - Model saved!\n",
      "Epoch [279/1000], New best loss: 0.3971 - Model saved!\n",
      "Epoch [280/1000], New best loss: 0.3971 - Model saved!\n",
      "Epoch [280/1000], Loss: 0.3971\n",
      "Epoch [281/1000], New best loss: 0.3970 - Model saved!\n",
      "Epoch [282/1000], New best loss: 0.3969 - Model saved!\n",
      "Epoch [283/1000], New best loss: 0.3968 - Model saved!\n",
      "Epoch [284/1000], New best loss: 0.3967 - Model saved!\n",
      "Epoch [285/1000], New best loss: 0.3966 - Model saved!\n",
      "Epoch [286/1000], New best loss: 0.3965 - Model saved!\n",
      "Epoch [287/1000], New best loss: 0.3964 - Model saved!\n",
      "Epoch [288/1000], New best loss: 0.3964 - Model saved!\n",
      "Epoch [289/1000], New best loss: 0.3963 - Model saved!\n",
      "Epoch [290/1000], New best loss: 0.3962 - Model saved!\n",
      "Epoch [290/1000], Loss: 0.3962\n",
      "Epoch [291/1000], New best loss: 0.3961 - Model saved!\n",
      "Epoch [292/1000], New best loss: 0.3961 - Model saved!\n",
      "Epoch [293/1000], New best loss: 0.3960 - Model saved!\n",
      "Epoch [294/1000], New best loss: 0.3958 - Model saved!\n",
      "Epoch [295/1000], New best loss: 0.3958 - Model saved!\n",
      "Epoch [296/1000], New best loss: 0.3957 - Model saved!\n",
      "Epoch [297/1000], New best loss: 0.3956 - Model saved!\n",
      "Epoch [298/1000], New best loss: 0.3955 - Model saved!\n",
      "Epoch [299/1000], New best loss: 0.3955 - Model saved!\n",
      "Epoch [300/1000], New best loss: 0.3953 - Model saved!\n",
      "Epoch [300/1000], Loss: 0.3953\n",
      "Epoch [301/1000], New best loss: 0.3952 - Model saved!\n",
      "Epoch [302/1000], New best loss: 0.3951 - Model saved!\n",
      "Epoch [303/1000], New best loss: 0.3951 - Model saved!\n",
      "Epoch [304/1000], New best loss: 0.3950 - Model saved!\n",
      "Epoch [305/1000], New best loss: 0.3950 - Model saved!\n",
      "Epoch [306/1000], New best loss: 0.3949 - Model saved!\n",
      "Epoch [307/1000], New best loss: 0.3949 - Model saved!\n",
      "Epoch [308/1000], New best loss: 0.3948 - Model saved!\n",
      "Epoch [309/1000], New best loss: 0.3948 - Model saved!\n",
      "Epoch [310/1000], New best loss: 0.3948 - Model saved!\n",
      "Epoch [310/1000], Loss: 0.3948\n",
      "Epoch [311/1000], New best loss: 0.3947 - Model saved!\n",
      "Epoch [312/1000], New best loss: 0.3947 - Model saved!\n",
      "Epoch [313/1000], New best loss: 0.3946 - Model saved!\n",
      "Epoch [314/1000], New best loss: 0.3946 - Model saved!\n",
      "Epoch [315/1000], New best loss: 0.3945 - Model saved!\n",
      "Epoch [316/1000], New best loss: 0.3945 - Model saved!\n",
      "Epoch [317/1000], New best loss: 0.3945 - Model saved!\n",
      "Epoch [318/1000], New best loss: 0.3944 - Model saved!\n",
      "Epoch [319/1000], New best loss: 0.3944 - Model saved!\n",
      "Epoch [320/1000], New best loss: 0.3943 - Model saved!\n",
      "Epoch [320/1000], Loss: 0.3943\n",
      "Epoch [321/1000], New best loss: 0.3943 - Model saved!\n",
      "Epoch [322/1000], New best loss: 0.3942 - Model saved!\n",
      "Epoch [323/1000], New best loss: 0.3942 - Model saved!\n",
      "Epoch [324/1000], New best loss: 0.3941 - Model saved!\n",
      "Epoch [325/1000], New best loss: 0.3941 - Model saved!\n",
      "Epoch [326/1000], New best loss: 0.3941 - Model saved!\n",
      "Epoch [327/1000], New best loss: 0.3940 - Model saved!\n",
      "Epoch [328/1000], New best loss: 0.3940 - Model saved!\n",
      "Epoch [329/1000], New best loss: 0.3939 - Model saved!\n",
      "Epoch [330/1000], New best loss: 0.3939 - Model saved!\n",
      "Epoch [330/1000], Loss: 0.3939\n",
      "Epoch [331/1000], New best loss: 0.3938 - Model saved!\n",
      "Epoch [332/1000], New best loss: 0.3938 - Model saved!\n",
      "Epoch [333/1000], New best loss: 0.3937 - Model saved!\n",
      "Epoch [334/1000], New best loss: 0.3937 - Model saved!\n",
      "Epoch [335/1000], New best loss: 0.3937 - Model saved!\n",
      "Epoch [336/1000], New best loss: 0.3937 - Model saved!\n",
      "Epoch [337/1000], New best loss: 0.3937 - Model saved!\n",
      "Epoch [338/1000], New best loss: 0.3936 - Model saved!\n",
      "Epoch [339/1000], New best loss: 0.3936 - Model saved!\n",
      "Epoch [340/1000], New best loss: 0.3936 - Model saved!\n",
      "Epoch [340/1000], Loss: 0.3936\n",
      "Epoch [341/1000], New best loss: 0.3936 - Model saved!\n",
      "Epoch [342/1000], New best loss: 0.3935 - Model saved!\n",
      "Epoch [343/1000], New best loss: 0.3935 - Model saved!\n",
      "Epoch [344/1000], New best loss: 0.3935 - Model saved!\n",
      "Epoch [345/1000], New best loss: 0.3935 - Model saved!\n",
      "Epoch [346/1000], New best loss: 0.3935 - Model saved!\n",
      "Epoch [347/1000], New best loss: 0.3934 - Model saved!\n",
      "Epoch [348/1000], New best loss: 0.3934 - Model saved!\n",
      "Epoch [349/1000], New best loss: 0.3934 - Model saved!\n",
      "Epoch [350/1000], New best loss: 0.3934 - Model saved!\n",
      "Epoch [350/1000], Loss: 0.3934\n",
      "Epoch [351/1000], New best loss: 0.3934 - Model saved!\n",
      "Epoch [352/1000], New best loss: 0.3933 - Model saved!\n",
      "Epoch [353/1000], New best loss: 0.3933 - Model saved!\n",
      "Epoch [354/1000], New best loss: 0.3933 - Model saved!\n",
      "Epoch [355/1000], New best loss: 0.3933 - Model saved!\n",
      "Epoch [356/1000], New best loss: 0.3932 - Model saved!\n",
      "Epoch [358/1000], New best loss: 0.3932 - Model saved!\n",
      "Epoch [359/1000], New best loss: 0.3932 - Model saved!\n",
      "Epoch [360/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [360/1000], Loss: 0.3931\n",
      "Epoch [361/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [362/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [363/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [364/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [365/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [366/1000], New best loss: 0.3931 - Model saved!\n",
      "Epoch [367/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [368/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [369/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [370/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [370/1000], Loss: 0.3930\n",
      "Epoch [371/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [372/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [373/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [374/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [375/1000], New best loss: 0.3930 - Model saved!\n",
      "Epoch [376/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [377/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [378/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [379/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [380/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [380/1000], Loss: 0.3929\n",
      "Epoch [381/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [382/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [383/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [384/1000], New best loss: 0.3929 - Model saved!\n",
      "Epoch [385/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [386/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [387/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [388/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [389/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [390/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [390/1000], Loss: 0.3928\n",
      "Epoch [391/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [392/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [393/1000], New best loss: 0.3928 - Model saved!\n",
      "Epoch [394/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [395/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [396/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [397/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [398/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [399/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [400/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [400/1000], Loss: 0.3927\n",
      "Epoch [401/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [402/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [403/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [404/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [405/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [406/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [407/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [408/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [410/1000], New best loss: 0.3927 - Model saved!\n",
      "Epoch [410/1000], Loss: 0.3927\n",
      "Epoch [411/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [413/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [414/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [415/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [416/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [417/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [418/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [419/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [420/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [420/1000], Loss: 0.3926\n",
      "Epoch [421/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [422/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [423/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [424/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [425/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [426/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [427/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [428/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [429/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [430/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [430/1000], Loss: 0.3926\n",
      "Epoch [431/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [432/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [433/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [434/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [435/1000], New best loss: 0.3926 - Model saved!\n",
      "Epoch [436/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [437/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [439/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [440/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [440/1000], Loss: 0.3925\n",
      "Epoch [441/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [442/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [443/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [444/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [446/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [447/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [448/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [449/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [450/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [450/1000], Loss: 0.3925\n",
      "Epoch [451/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [452/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [453/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [454/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [455/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [456/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [457/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [458/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [459/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [460/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [460/1000], Loss: 0.3925\n",
      "Epoch [461/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [463/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [464/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [465/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [466/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [468/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [469/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [470/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [470/1000], Loss: 0.3925\n",
      "Epoch [471/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [472/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [473/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [474/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [475/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [476/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [478/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [479/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [480/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [480/1000], Loss: 0.3925\n",
      "Epoch [481/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [482/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [484/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [485/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [486/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [487/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [488/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [489/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [490/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [490/1000], Loss: 0.3925\n",
      "Epoch [491/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [493/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [495/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [496/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [497/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [499/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [500/1000], New best loss: 0.3925 - Model saved!\n",
      "Epoch [500/1000], Loss: 0.3925\n",
      "Epoch [501/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [503/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [504/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [505/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [506/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [508/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [509/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [510/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [510/1000], Loss: 0.3924\n",
      "Epoch [511/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [512/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [513/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [514/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [515/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [516/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [517/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [518/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [520/1000], Loss: 0.3924\n",
      "Epoch [521/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [522/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [524/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [525/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [527/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [528/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [529/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [530/1000], Loss: 0.3924\n",
      "Epoch [532/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [533/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [534/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [535/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [536/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [537/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [540/1000], Loss: 0.3924\n",
      "Epoch [541/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [544/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [546/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [548/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [549/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [550/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [550/1000], Loss: 0.3924\n",
      "Epoch [551/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [552/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [557/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [559/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [560/1000], Loss: 0.3924\n",
      "Epoch [562/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [569/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [570/1000], Loss: 0.3924\n",
      "Epoch [571/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [572/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [573/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [576/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [577/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [578/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [579/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [580/1000], Loss: 0.3924\n",
      "Epoch [581/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [583/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [590/1000], Loss: 0.3924\n",
      "Epoch [595/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [596/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [599/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [600/1000], Loss: 0.3924\n",
      "Epoch [609/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [610/1000], Loss: 0.3924\n",
      "Epoch [619/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [620/1000], Loss: 0.3924\n",
      "Epoch [621/1000], New best loss: 0.3924 - Model saved!\n",
      "Epoch [630/1000], Loss: 0.3924\n",
      "Epoch [640/1000], Loss: 0.3924\n",
      "Epoch [650/1000], Loss: 0.3924\n",
      "Epoch [660/1000], Loss: 0.3924\n",
      "Epoch [670/1000], Loss: 0.3924\n",
      "Epoch [680/1000], Loss: 0.3924\n",
      "Epoch [690/1000], Loss: 0.3924\n",
      "Epoch [700/1000], Loss: 0.3924\n",
      "Epoch [710/1000], Loss: 0.3924\n",
      "Epoch [720/1000], Loss: 0.3924\n",
      "Epoch [730/1000], Loss: 0.3924\n",
      "Epoch [740/1000], Loss: 0.3924\n",
      "Epoch [750/1000], Loss: 0.3924\n",
      "Epoch [760/1000], Loss: 0.3924\n",
      "Epoch [770/1000], Loss: 0.3924\n",
      "Epoch [780/1000], Loss: 0.3924\n",
      "Epoch [790/1000], Loss: 0.3924\n",
      "Epoch [800/1000], Loss: 0.3924\n",
      "Epoch [810/1000], Loss: 0.3924\n",
      "Epoch [820/1000], Loss: 0.3924\n",
      "Epoch [830/1000], Loss: 0.3924\n",
      "Epoch [840/1000], Loss: 0.3924\n",
      "Epoch [850/1000], Loss: 0.3924\n",
      "Epoch [860/1000], Loss: 0.3924\n",
      "Epoch [870/1000], Loss: 0.3924\n",
      "Epoch [880/1000], Loss: 0.3924\n",
      "Epoch [890/1000], Loss: 0.3924\n",
      "Epoch [900/1000], Loss: 0.3924\n",
      "Epoch [910/1000], Loss: 0.3924\n",
      "Epoch [920/1000], Loss: 0.3924\n",
      "Epoch [930/1000], Loss: 0.3924\n",
      "Epoch [940/1000], Loss: 0.3924\n",
      "Epoch [950/1000], Loss: 0.3924\n",
      "Epoch [960/1000], Loss: 0.3924\n",
      "Epoch [970/1000], Loss: 0.3924\n",
      "Epoch [980/1000], Loss: 0.3924\n",
      "Epoch [990/1000], Loss: 0.3924\n",
      "Epoch [1000/1000], Loss: 0.3924\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model for predictions...\n",
      "Loaded best model from epoch 620 with loss: 0.3924\n",
      "Generating predictions for test inputs...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to arc_predictions.pt\n",
      "\n",
      "Training completed!\n",
      "Final loss: 0.3924\n",
      "Generated predictions for 120 test problems\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "NUM_OF_EPOCHS = 1000\n",
    "\n",
    "class ARCDataset(Dataset):\n",
    "    \"\"\"Dataset class for ARC AGI training data\"\"\"\n",
    "    def __init__(self, training_pairs):\n",
    "        self.data = []\n",
    "        for problem_id, (input_tensor, output_tensor) in training_pairs.items():\n",
    "            self.data.append((input_tensor, output_tensor))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class ARCNeuralNetwork(nn.Module):\n",
    "    \"\"\"Deep neural network for ARC AGI tasks\"\"\"\n",
    "    def __init__(self, input_channels=10, output_channels=10, hidden_dim=128):\n",
    "        super(ARCNeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Encoder: Process input grid\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 15x15\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Decoder: Generate output grid\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),  # 30x30\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, output_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism for pattern recognition\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=512, num_heads=8, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 30, 30, 10)\n",
    "        # Convert to (batch_size, 10, 30, 30) for conv layers\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Encode\n",
    "        encoded = self.encoder(x)  # (batch_size, 512, 15, 15)\n",
    "        \n",
    "        # Apply attention\n",
    "        batch_size, channels, height, width = encoded.shape\n",
    "        encoded_flat = encoded.view(batch_size, channels, -1).permute(0, 2, 1)  # (batch_size, 225, 512)\n",
    "        attended, _ = self.attention(encoded_flat, encoded_flat, encoded_flat)\n",
    "        attended = attended.permute(0, 2, 1).view(batch_size, channels, height, width)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(attended)  # (batch_size, 10, 30, 30)\n",
    "        \n",
    "        # Convert back to (batch_size, 30, 30, 10)\n",
    "        output = decoded.permute(0, 2, 3, 1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def one_hot_2d_matrix(matrix, num_classes=10, max_size=30):\n",
    "    \"\"\"Convert a 2D matrix of values 0-9 to a 30x30x10 one-hot tensor.\"\"\"\n",
    "    h, w = len(matrix), len(matrix[0])\n",
    "    arr = np.full((max_size, max_size), -1, dtype=np.int64)\n",
    "    arr[:h, :w] = np.array(matrix)\n",
    "    one_hot = np.eye(num_classes)[arr]  # shape: (30, 30, 10)\n",
    "    return torch.tensor(one_hot, dtype=torch.float32)\n",
    "\n",
    "def load_arc_data(json_path):\n",
    "    \"\"\"Load ARC AGI data from JSON file\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    training_pairs = {}  # Dict of problem_id and corresponding (input_tensor, output_tensor)\n",
    "    testing_inputs = {}  # Dict of problem_id and corresponding input_tensors\n",
    "\n",
    "    first = True\n",
    "    first_problem_id = None\n",
    "    \n",
    "    for problem_id, problem in data.items():\n",
    "        # Train data\n",
    "        for pair in problem['train']:\n",
    "            if first:\n",
    "                first_problem_id = problem_id\n",
    "                print(\"First Problem ID:\", first_problem_id)\n",
    "                print(\"First Pair:\")\n",
    "                pprint(pair)\n",
    "            inp = one_hot_2d_matrix(pair['input'])\n",
    "            out = one_hot_2d_matrix(pair['output'])\n",
    "            if first:\n",
    "                print(\"First Input shape:\", inp.shape)\n",
    "                print(\"First Output shape:\", out.shape)\n",
    "                first = False\n",
    "            training_pairs[problem_id] = (inp, out)\n",
    "        # Test data\n",
    "        for test_case in problem['test']:\n",
    "            inp = one_hot_2d_matrix(test_case['input'])\n",
    "            testing_inputs[problem_id] = inp\n",
    "\n",
    "    return first_problem_id, training_pairs, testing_inputs\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=100, device='cpu', start_epoch=0):\n",
    "    \"\"\"Train the neural network\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    # Load checkpoint if starting from a previous state\n",
    "    if start_epoch > 0:\n",
    "        try:\n",
    "            # Try to load from the specified path first\n",
    "            checkpoint_path = '/kaggle/input/suyambhoo/pytorch/arc-agi-2/1/best_model.chkpt'\n",
    "            if torch.cuda.is_available():\n",
    "                checkpoint = torch.load(checkpoint_path)\n",
    "            else:\n",
    "                checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            \n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            best_loss = checkpoint['loss']\n",
    "            print(f\"Resuming training from epoch {start_epoch} with best loss: {best_loss:.4f}\")\n",
    "            print(f\"Loaded optimizer state from: {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading optimizer state from {checkpoint_path}: {e}\")\n",
    "            print(\"Using fresh optimizer state.\")\n",
    "            best_loss = float('inf')\n",
    "    else:\n",
    "        best_loss = float('inf')\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    print(f\"Training for {num_epochs} epochs starting from epoch {start_epoch}...\")\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Reshape for loss calculation\n",
    "            outputs_flat = outputs.reshape(-1, 10)  # (batch_size * 30 * 30, 10)\n",
    "            targets_flat = torch.argmax(targets, dim=-1).reshape(-1)  # (batch_size * 30 * 30)\n",
    "            \n",
    "            loss = criterion(outputs_flat, targets_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, 'best_model.chkpt')\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], New best loss: {avg_loss:.4f} - Model saved!')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def check_existing_checkpoint(checkpoint_path='/kaggle/input/suyambhoo/pytorch/arc-agi-2/1/best_model.chkpt'):\n",
    "    \"\"\"Check if a checkpoint file exists and return the starting epoch\"\"\"\n",
    "    import os\n",
    "    print(f\"Checking for checkpoint at: {checkpoint_path}\")\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                checkpoint = torch.load(checkpoint_path)\n",
    "            else:\n",
    "                checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            start_epoch = checkpoint['epoch'] + 1  # Start from next epoch\n",
    "            print(f\" Found existing checkpoint from epoch {checkpoint['epoch']} with loss: {checkpoint['loss']:.4f}\")\n",
    "            print(f\" Checkpoint loaded from: {checkpoint_path}\")\n",
    "            return start_epoch\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading checkpoint from {checkpoint_path}: {e}\")\n",
    "            print(\"Starting training from scratch.\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\" No existing checkpoint found at {checkpoint_path}. Starting training from scratch.\")\n",
    "        return 0\n",
    "\n",
    "def load_best_model(model, checkpoint_path='/kaggle/input/suyambhoo/pytorch/arc-agi-2/1/best_model.chkpt', device='cpu'):\n",
    "    \"\"\"Load the best model from checkpoint\"\"\"\n",
    "    print(f\"Loading model from: {checkpoint_path}\")\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "        else:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\" Loaded best model from epoch {checkpoint['epoch']} with loss: {checkpoint['loss']:.4f}\")\n",
    "        print(f\" Model loaded from: {checkpoint_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading model from {checkpoint_path}: {e}\")\n",
    "        print(\"Using randomly initialized model.\")\n",
    "        return model\n",
    "\n",
    "def generate_predictions(model, test_inputs, device='cpu'):\n",
    "    \"\"\"Generate predictions for test inputs\"\"\"\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for problem_id, input_tensor in test_inputs.items():\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            output = model(input_tensor)\n",
    "            \n",
    "            # Convert one-hot back to indices\n",
    "            predicted_indices = torch.argmax(output, dim=-1).squeeze(0)  # (30, 30)\n",
    "            predictions[problem_id] = predicted_indices.cpu().numpy()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def visualize_results(input_tensor, target_tensor, predicted_tensor, problem_id):\n",
    "    \"\"\"Visualize input, target, and prediction\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Convert one-hot to indices for visualization\n",
    "    input_indices = torch.argmax(input_tensor, dim=-1).numpy()\n",
    "    target_indices = torch.argmax(target_tensor, dim=-1).numpy()\n",
    "    \n",
    "    axes[0].imshow(input_indices, cmap='tab10', vmin=0, vmax=9)\n",
    "    axes[0].set_title('Input')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(target_indices, cmap='tab10', vmin=0, vmax=9)\n",
    "    axes[1].set_title('Target')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(predicted_tensor, cmap='tab10', vmin=0, vmax=9)\n",
    "    axes[2].set_title('Prediction')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Problem ID: {problem_id}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'arc_results_{problem_id}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading ARC AGI data...\")\n",
    "    first_problem_id, training_pairs, testing_inputs = load_arc_data('/kaggle/input/arc-prize-2025/arc-agi_evaluation_challenges.json')\n",
    "    print(f\"Loaded {len(training_pairs)} training pairs and {len(testing_inputs)} test inputs.\")\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = ARCDataset(training_pairs)\n",
    "    train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ARCNeuralNetwork().to(device)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Check for existing checkpoint from the specified path\n",
    "    start_epoch = check_existing_checkpoint('/kaggle/input/suyambhoo/pytorch/arc-agi-2/1/best_model.chkpt')\n",
    "    \n",
    "    # If checkpoint exists, load the model state before training\n",
    "    if start_epoch > 0:\n",
    "        model = load_best_model(model, '/kaggle/input/suyambhoo/pytorch/arc-agi-2/1/best_model.chkpt', device=device)\n",
    "    \n",
    "    # Train model\n",
    "    losses = train_model(model, train_loader, num_epochs=NUM_OF_EPOCHS, device=device, start_epoch=start_epoch)\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Load best model for predictions (use the local best model that was saved during training)\n",
    "    print(\"Loading best model for predictions...\")\n",
    "    model = load_best_model(model, 'best_model.chkpt', device=device)\n",
    "    \n",
    "    # Generate predictions\n",
    "    print(\"Generating predictions for test inputs...\")\n",
    "    predictions = generate_predictions(model, testing_inputs, device=device)\n",
    "    \n",
    "    # Visualize results for first problem\n",
    "    if first_problem_id in training_pairs and first_problem_id in testing_inputs:\n",
    "        input_tensor, target_tensor = training_pairs[first_problem_id]\n",
    "        predicted_tensor = predictions[first_problem_id]\n",
    "        visualize_results(input_tensor, target_tensor, predicted_tensor, first_problem_id)\n",
    "    \n",
    "    # Save predictions\n",
    "    torch.save(predictions, 'arc_predictions.pt')\n",
    "    print(\"Predictions saved to arc_predictions.pt\")\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nTraining completed!\")\n",
    "    print(f\"Final loss: {losses[-1]:.4f}\")\n",
    "    print(f\"Generated predictions for {len(predictions)} test problems\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 415341,
     "modelInstanceId": 396904,
     "sourceId": 499631,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
